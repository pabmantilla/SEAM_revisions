{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79baa060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# TensorFlow/Keras imports for model loading\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# SEAM imports\n",
    "import seam\n",
    "from seam import Compiler, Attributer, Clusterer, MetaExplainer, Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55732f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing data/deepstarr_data.h5\n",
      "\n",
      "Data loaded successfully!\n",
      "X_test shape: (41186, 249, 4)\n",
      "\n",
      "Summary:\n",
      "             shape    dtype  min  max  num_sequences\n",
      "0  (41186, 249, 4)  float32  0.0  1.0          41186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['shape', 'dtype', 'min', 'max', 'num_sequences'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download data if not present\n",
    "data_file = os.path.join(data_dir, 'deepstarr_data.h5')\n",
    "if not os.path.exists(data_file):\n",
    "    print(\"Downloading deepstarr_data.h5...\")\n",
    "    url = 'https://www.dropbox.com/scl/fi/cya4ntqk2o8yftxql52lu/deepstarr_data.h5?rlkey=5ly363vqjb3vaw2euw2dhsjo3&st=6eod6fg8&dl=1'\n",
    "    subprocess.run(['wget', '-O', data_file, url], check=True)\n",
    "else:\n",
    "    print(f\"Using existing {data_file}\")\n",
    "\n",
    "# Load data\n",
    "with h5py.File(data_file, 'r') as dataset:\n",
    "    X_test = np.array(dataset['x_test']).astype(np.float32)\n",
    "\n",
    "# Create a summary dataframe\n",
    "df = pd.DataFrame({\n",
    "    'shape': [X_test.shape],\n",
    "    'dtype': [X_test.dtype],\n",
    "    'min': [X_test.min()],\n",
    "    'max': [X_test.max()],\n",
    "    'num_sequences': [X_test.shape[0]]\n",
    "})\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(df)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3c4a105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing ../data/deepstarr.model.json\n",
      "Using existing ../data/deepstarr.model.h5\n",
      "\n",
      "Model loaded successfully!\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "\n",
      "Wild-type predictions: (2.8394015, 0.8605407)\n",
      "Model input shape: (None, 249, 4)\n",
      "Model output shape: [(None, 1), (None, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Download and load the DeepSTARR model\n",
    "model_dir = '../data'\n",
    "\n",
    "# Download model files if not present\n",
    "model_json_file = os.path.join(model_dir, 'deepstarr.model.json')\n",
    "model_weights_file = os.path.join(model_dir, 'deepstarr.model.h5')\n",
    "\n",
    "if not os.path.exists(model_json_file):\n",
    "    print(\"Downloading deepstarr.model.json...\")\n",
    "    url = 'https://www.dropbox.com/scl/fi/y1mwsqpv2e514md9t68jz/deepstarr.model.json?rlkey=cdwhstqf96fibshes2aov6t1e&st=9a0c5skz&dl=1'\n",
    "    urlretrieve(url, model_json_file)\n",
    "else:\n",
    "    print(f\"Using existing {model_json_file}\")\n",
    "\n",
    "if not os.path.exists(model_weights_file):\n",
    "    print(\"Downloading deepstarr.model.h5...\")\n",
    "    url = 'https://www.dropbox.com/scl/fi/6nl6e2hofyw70lh99h3uk/deepstarr.model.h5?rlkey=hqfnivn199xa54bjh8dn2jpaf&st=l4jig4ky&dl=1'\n",
    "    urlretrieve(url, model_weights_file)\n",
    "else:\n",
    "    print(f\"Using existing {model_weights_file}\")\n",
    "\n",
    "# Load the model architecture from JSON\n",
    "with open(model_json_file, 'r') as f:\n",
    "    model_json = f.read()\n",
    "\n",
    "model = model_from_json(model_json, custom_objects={'Functional': tf.keras.Model})\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(113)\n",
    "random.seed(0)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_weights(model_weights_file)\n",
    "num_tasks = 2  # Dev [0] and Hk [1]\n",
    "\n",
    "alphabet = ['A','C','G','T']\n",
    "\n",
    "x_ref = X_test[0]\n",
    "x_ref = np.expand_dims(x_ref,0)\n",
    "\n",
    "\n",
    "# Define mutagenesis window for sequence\n",
    "seq_length = x_ref.shape[1]\n",
    "mut_window = [0, seq_length]  # [start_position, stop_position]\n",
    "print(\"\\nModel loaded successfully!\")\n",
    "\n",
    "# Forward pass to get output for the specific head\n",
    "output = model(x_ref)\n",
    "predd,predh = model.predict(x_ref)[0], model.predict(x_ref)[1]\n",
    "print(f\"\\nWild-type predictions: {predd[0][0], predh[0][0]}\")\n",
    "print(f\"Model input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bea63c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing model architecture: models/deepstarr/deepstarr.model.json\n",
      "Using existing model weights: models/deepstarr/deepstarr.model.h5\n",
      "✓ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Create a dedicated model directory\n",
    "model_dir = 'models/deepstarr'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "model_json_file = os.path.join(model_dir, 'deepstarr.model.json')\n",
    "model_weights_file = os.path.join(model_dir, 'deepstarr.model.h5')\n",
    "\n",
    "# Download model architecture if not present\n",
    "if not os.path.exists(model_json_file):\n",
    "    print(\"Downloading deepstarr.model.json...\")\n",
    "    url = 'https://www.dropbox.com/scl/fi/y1mwsqpv2e514md9t68jz/deepstarr.model.json?rlkey=cdwhstqf96fibshes2aov6t1e&st=9a0c5skz&dl=1'\n",
    "    urlretrieve(url, model_json_file)\n",
    "    print(f\"Saved to {model_json_file}\")\n",
    "else:\n",
    "    print(f\"Using existing model architecture: {model_json_file}\")\n",
    "\n",
    "# Download model weights if not present\n",
    "if not os.path.exists(model_weights_file):\n",
    "    print(\"Downloading deepstarr.model.h5...\")\n",
    "    url = 'https://www.dropbox.com/scl/fi/6nl6e2hofyw70lh99h3uk/deepstarr.model.h5?rlkey=hqfnivn199xa54bjh8dn2jpaf&st=l4jig4ky&dl=1'\n",
    "    urlretrieve(url, model_weights_file)\n",
    "    print(f\"Saved to {model_weights_file}\")\n",
    "else:\n",
    "    print(f\"Using existing model weights: {model_weights_file}\")\n",
    "\n",
    "# Load the model\n",
    "with open(model_json_file, 'r') as f:\n",
    "    model_json = f.read()\n",
    "\n",
    "model = model_from_json(model_json, custom_objects={'Functional': tf.keras.Model})\n",
    "model.load_weights(model_weights_file)\n",
    "\n",
    "print(\"✓ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4851c5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## paper seqs\n",
    "\n",
    "paper_loci_idx = [20647, 22612, 4071, 22627, 21069, 13748]\n",
    "dev_mask = [0,1,0,0, 1, 1]\n",
    "paper_loci = []\n",
    "for i in paper_loci_idx:\n",
    "    seq = X_test[i]\n",
    "    paper_loci.append(seq)\n",
    "\n",
    "paper_loci[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ff64236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting or switching heads\n",
      "17977\n",
      "2.9907937\n",
      "21916\n",
      "2.2963743\n",
      "21289\n",
      "2.7399046\n",
      "3881\n",
      "2.1586962\n",
      "266\n",
      "3.8290648\n",
      "5 dev found\n",
      "Starting or switching heads\n",
      "31742\n",
      "3.5934138\n",
      "12962\n",
      "2.2718976\n",
      "12053\n",
      "5.3012533\n",
      "24723\n",
      "4.471285\n",
      "12279\n",
      "3.426753\n",
      "5 hk found\n",
      "We have isolated 5 dev loci and5 hk loci with activity > 2\n",
      "[3.5934138, 2.2718976, 5.3012533, 4.471285, 3.426753]\n"
     ]
    }
   ],
   "source": [
    "## randomly selectt 5 seq of high (<2 activity) for each head\n",
    "heads = [0,1]\n",
    "dev_loci = []\n",
    "dev_pred = []\n",
    "hk_loci = []\n",
    "hk_pred = []\n",
    "dev_idx=[]\n",
    "hk_idx =[]\n",
    "h=0\n",
    "j=0\n",
    "go=True\n",
    "threshold = 2\n",
    "\n",
    "for i in heads:\n",
    "    print(\"Starting or switching heads\")\n",
    "    if h != 5:\n",
    "        go = True\n",
    "    while go:\n",
    "        idx = int(np.random.uniform(0, len(X_test)))\n",
    "        seq = X_test[idx]\n",
    "        seq = np.expand_dims(seq,0)\n",
    "\n",
    "        pred = model.predict(seq, verbose=0)[i][0][0]\n",
    "        if i==0 and pred > threshold:\n",
    "            print(idx)\n",
    "            print(pred)\n",
    "            dev_loci.append(seq[0])\n",
    "            dev_idx.append(idx)\n",
    "            dev_pred.append(pred)\n",
    "            j+=1\n",
    "            if j==5:\n",
    "                go=False\n",
    "                print(\"5 dev found\")\n",
    "        if i==1 and pred>threshold:\n",
    "            print(idx)\n",
    "            print(pred)\n",
    "            hk_loci.append(seq[0])\n",
    "            hk_idx.append(idx)\n",
    "            hk_pred.append(pred)\n",
    "\n",
    "            h+=1\n",
    "            if h == 5:\n",
    "                go=False\n",
    "                print(\"5 hk found\")\n",
    "\n",
    "\n",
    "print(f\"We have isolated {len(dev_loci)} dev loci and{len(hk_loci)} hk loci with activity > {threshold}\")\n",
    "print(hk_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "622cbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "(3,)\n",
      "Paper loci has added 3 dev seqs and 3 hk seqs\n",
      "Total is now Dev: 8 and Hk: 8\n"
     ]
    }
   ],
   "source": [
    "## Add random and paper together for each head\n",
    "\n",
    "dev_mask_bool = np.array(dev_mask, dtype=bool)\n",
    "paper_loci_array = np.array(paper_loci)\n",
    "\n",
    "\n",
    "\n",
    "dev_paper_loci = paper_loci_array[dev_mask_bool].tolist()\n",
    "hk_paper_loci = paper_loci_array[~dev_mask_bool].tolist()\n",
    "\n",
    "\n",
    "dev_paper_pred = model.predict(np.array(dev_paper_loci))[0].flatten()\n",
    "hk_paper_pred = model.predict(np.array(hk_paper_loci))[1].flatten() \n",
    "\n",
    "dev_loci.extend(dev_paper_loci)\n",
    "hk_loci.extend(hk_paper_loci)\n",
    "\n",
    "hk_paper_pred = np.squeeze(hk_paper_pred)\n",
    "print(hk_paper_pred.shape)\n",
    "dev_pred.extend(dev_paper_pred)\n",
    "hk_pred.extend(hk_paper_pred)\n",
    "\n",
    "\n",
    "dev_paper_idx = [paper_loci_idx[i] for i, m in enumerate(dev_mask) if m]\n",
    "hk_paper_idx = [paper_loci_idx[i] for i, m in enumerate(dev_mask) if not m]\n",
    "\n",
    "dev_idx.extend(dev_paper_idx)\n",
    "hk_idx.extend(hk_paper_idx)\n",
    "\n",
    "print(f'Paper loci has added {len(dev_paper_loci)} dev seqs and {len(hk_paper_loci)} hk seqs')\n",
    "print(f'Total is now Dev: {len(dev_loci)} and Hk: {len(hk_loci)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d08228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_idx</th>\n",
       "      <th>sequence</th>\n",
       "      <th>activity</th>\n",
       "      <th>ohe_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31742</td>\n",
       "      <td>ACCATCGGGTAGTGCCGCTGATTGCAGCACAGCTGATCACGTTGCC...</td>\n",
       "      <td>3.593414</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12962</td>\n",
       "      <td>ACGCAAAGGTATAATTAGATACAATGAAAATAAGTTTCTTGCATGC...</td>\n",
       "      <td>2.271898</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12053</td>\n",
       "      <td>TATCCAGTCGGTGACCTGGTCGGGCGTCCACTCGGCGATGTTGATG...</td>\n",
       "      <td>5.301253</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24723</td>\n",
       "      <td>CCTCACCGCCTAAAACAACAAGCGCATATGTTTGGCTTATCGATAG...</td>\n",
       "      <td>4.471285</td>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12279</td>\n",
       "      <td>TCCGTTTTCTAGCCGTTTAATAGCTAGAGCTCCATCACTGTCGGCG...</td>\n",
       "      <td>3.426753</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20647</td>\n",
       "      <td>ATAACTTTAATAGCAAGCGAGTCTCTTTATTATCAAATCGCTTAAT...</td>\n",
       "      <td>5.298523</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4071</td>\n",
       "      <td>AATAATCAAGGCGCGGCTGGCATCATCTTCCTCACTCCGATCCGCG...</td>\n",
       "      <td>-0.491585</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22627</td>\n",
       "      <td>GTTAACTAGCTATGCGAGTACAACTTGTAAATAGAACATTCAAATT...</td>\n",
       "      <td>3.446424</td>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_idx                                           sequence  activity  \\\n",
       "0     31742  ACCATCGGGTAGTGCCGCTGATTGCAGCACAGCTGATCACGTTGCC...  3.593414   \n",
       "1     12962  ACGCAAAGGTATAATTAGATACAATGAAAATAAGTTTCTTGCATGC...  2.271898   \n",
       "2     12053  TATCCAGTCGGTGACCTGGTCGGGCGTCCACTCGGCGATGTTGATG...  5.301253   \n",
       "3     24723  CCTCACCGCCTAAAACAACAAGCGCATATGTTTGGCTTATCGATAG...  4.471285   \n",
       "4     12279  TCCGTTTTCTAGCCGTTTAATAGCTAGAGCTCCATCACTGTCGGCG...  3.426753   \n",
       "5     20647  ATAACTTTAATAGCAAGCGAGTCTCTTTATTATCAAATCGCTTAAT...  5.298523   \n",
       "6      4071  AATAATCAAGGCGCGGCTGGCATCATCTTCCTCACTCCGATCCGCG... -0.491585   \n",
       "7     22627  GTTAACTAGCTATGCGAGTACAACTTGTAAATAGAACATTCAAATT...  3.446424   \n",
       "\n",
       "                                             ohe_seq  \n",
       "0  [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...  \n",
       "1  [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...  \n",
       "2  [[0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0], [...  \n",
       "3  [[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [...  \n",
       "4  [[0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0], [...  \n",
       "5  [[1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...  \n",
       "6  [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [...  \n",
       "7  [[0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0], [...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save library\n",
    "from seam.utils import oh2seq\n",
    "string_seqs_dev = []\n",
    "string_seqs_hk = []\n",
    "\n",
    "for i in dev_loci:\n",
    "    loci = np.squeeze(i)\n",
    "    str = oh2seq(loci)\n",
    "    string_seqs_dev.append(str)\n",
    "\n",
    "for i in hk_loci:\n",
    "    loci = np.squeeze(i)\n",
    "    str = oh2seq(loci)\n",
    "    string_seqs_hk.append(str)\n",
    "\n",
    "dev_hyperparam_library = pd.DataFrame({\n",
    "    \"test_idx\": dev_idx,\n",
    "    \"sequence\": string_seqs_dev,\n",
    "    \"activity\": dev_pred,\n",
    "    \"ohe_seq\": dev_loci\n",
    "})\n",
    "print(len(hk_pred))\n",
    "\n",
    "hk_hyperparam_library = pd.DataFrame({\n",
    "    \"test_idx\": hk_idx,\n",
    "    \"sequence\": string_seqs_hk,\n",
    "    \"activity\": hk_pred,\n",
    "    \"ohe_seq\": hk_loci\n",
    "})\n",
    "\n",
    "\n",
    "hk_hyperparam_library.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fb9b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save both libraries together\n",
    "with open('libraries/hyperparam_libraries.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'dev': dev_hyperparam_library,\n",
    "        'hk': hk_hyperparam_library\n",
    "    }, f)\n",
    "\n",
    "# Load later\n",
    "#with open('libraries/hyperparam_libraries.pkl', 'rb') as f:\n",
    "    #libraries = pickle.load(f)\n",
    "    #dev_lib = libraries['dev']\n",
    "    #hk_lib = libraries['hk']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (SEAM)",
   "language": "python",
   "name": "seam_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
