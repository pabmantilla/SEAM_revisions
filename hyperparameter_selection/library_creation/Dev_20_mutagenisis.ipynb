{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c29d8d39",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-23 10:47:53.767455: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-01-23 10:47:53.891948: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-23 10:47:53.895798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:53.895813: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2026-01-23 10:47:54.335563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:54.335703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:54.335709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "# TensorFlow/Keras imports for model loading\n",
        "import tensorflow as tf\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# SQUID imports for mutagenesis\n",
        "import squid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a5417dab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 23 Dev_20 sequences\n",
            "Columns: ['test_idx', 'sequence', 'activity', 'ohe_seq']\n",
            "Model loaded successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-23 10:47:57.131845: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.131957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/python37/lib\n",
            "2026-01-23 10:47:57.132638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2026-01-23 10:47:57.132919: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Load Dev_20 library\n",
        "with open('Dev_20_library/Dev_20/dev_20_library.pkl', 'rb') as f:\n",
        "    libraries = pickle.load(f)\n",
        "    dev_loci = libraries['dev']\n",
        "\n",
        "print(f\"Loaded {len(dev_loci)} Dev_20 sequences\")\n",
        "print(f\"Columns: {dev_loci.columns.tolist()}\")\n",
        "\n",
        "# Load DeepSTARR model\n",
        "model_dir = '../data_and_models/models'\n",
        "\n",
        "model_json_file = os.path.join(model_dir, 'deepstarr.model.json')\n",
        "model_weights_file = os.path.join(model_dir, 'deepstarr.model.h5')\n",
        "\n",
        "with open(model_json_file, 'r') as f:\n",
        "    model_json = f.read()\n",
        "\n",
        "model = model_from_json(model_json, custom_objects={'Functional': tf.keras.Model})\n",
        "model.load_weights(model_weights_file)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fc22a619",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to save library to HDF5\n",
        "def save_library(filepath, sequences, predictions, original_idx):\n",
        "    \"\"\"Save mutagenesis library to HDF5 file.\"\"\"\n",
        "    n_samples = len(sequences)\n",
        "    with h5py.File(filepath, 'w') as f:\n",
        "        f.create_dataset('sequences', data=sequences, compression='gzip', compression_opts=4)\n",
        "        f.create_dataset('predictions', data=predictions, compression='gzip', compression_opts=4)\n",
        "        # Add library_index for consistent subsetting (0 to n_samples-1)\n",
        "        f.create_dataset('library_index', data=np.arange(n_samples), compression='gzip', compression_opts=4)\n",
        "        f.attrs['original_idx'] = original_idx\n",
        "        f.attrs['n_samples'] = n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9ac5fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 23 sequences\n",
            "\n",
            "Building in silico MAVE...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Mutagenesis: 100%|██████████| 100000/100000 [00:04<00:00, 24959.74it/s]\n",
            "Inference: 100%|██████████| 195/195 [00:06<00:00, 30.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/23] Created seq_22612/100K.h5\n",
            "\n",
            "Building in silico MAVE...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Mutagenesis: 100%|██████████| 100000/100000 [00:03<00:00, 27890.59it/s]\n",
            "Inference:  47%|████▋     | 91/195 [00:02<00:03, 31.25it/s]"
          ]
        }
      ],
      "source": [
        "# Generate 100K mutagenesis libraries for each Dev_20 sequence\n",
        "task_index = 0  # 0 for Dev\n",
        "x_seqs = dev_loci[\"ohe_seq\"]\n",
        "seq_indices = dev_loci[\"test_idx\"]\n",
        "\n",
        "print(f\"Processing {len(x_seqs)} sequences\")\n",
        "\n",
        "for i, (x_seq, idx) in enumerate(zip(x_seqs, seq_indices)):\n",
        "    output_dir = f'Dev_20_mutagenisis_library/Dev/seq_{idx}'\n",
        "    output_file = f'{output_dir}/100K.h5'\n",
        "    \n",
        "    # Check if library already exists\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Skipping seq_{idx} - already exists\")\n",
        "        continue\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    x_seq = np.array(x_seq)\n",
        "    \n",
        "    # Create predictor\n",
        "    pred_generator = squid.predictor.ScalarPredictor(\n",
        "        pred_fun=model.predict_on_batch,\n",
        "        task_idx=task_index,\n",
        "        batch_size=512\n",
        "    )\n",
        "    \n",
        "    # Create mutagenizer\n",
        "    mut_generator = squid.mutagenizer.RandomMutagenesis(\n",
        "        mut_rate=0.10,\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    # Create MAVE\n",
        "    mave = squid.mave.InSilicoMAVE(\n",
        "        mut_generator,\n",
        "        pred_generator,\n",
        "        249,\n",
        "        mut_window=[0, 249]\n",
        "    )\n",
        "    \n",
        "    # Generate 100K mutant sequences\n",
        "    x_mut, y_mut = mave.generate(x_seq, num_sim=100000)\n",
        "    \n",
        "    # Save library\n",
        "    save_library(output_file, x_mut, y_mut, idx)\n",
        "    print(f\"[{i+1}/{len(x_seqs)}] Created seq_{idx}/100K.h5\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f09cda6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "seam-revisions (UV)",
      "language": "python",
      "name": "seam_revisions_uv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
